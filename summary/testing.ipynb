{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import ollama\n",
    "from pydantic import BaseModel\n",
    "import os \n",
    "import json \n",
    "import requests\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummaryResult(BaseModel):\n",
    "    summary: str\n",
    "    code: str\n",
    "    metadata: dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting code summary generation for repository: /Users/jerometh/Projects/CDS/smart-search/summary\n",
      "parse function read file\n",
      "Error generating summary: 'response'\n",
      "Error generating summary: 'response'\n",
      "Error generating summary: 'response'\n",
      "Error generating summary: 'response'\n",
      "Error generating summary: 'response'\n",
      "Error generating summary: 'response'\n",
      "Error generating summary: 'response'\n",
      "Error generating summary: 'response'\n",
      "Error generating summary: 'response'\n",
      "Error generating summary: 'response'\n",
      "Error generating summary: 'response'\n",
      "Error generating summary: 'response'\n",
      "Error generating summary: 'response'\n",
      "parse function read file\n",
      "Error generating summary: 'response'\n",
      "Error generating summary: 'response'\n",
      "Error generating summary: 'response'\n",
      "Error generating summary: 'response'\n",
      "Error generating summary: 'response'\n",
      "Error generating summary: 'response'\n",
      "parse function read file\n",
      "Error generating summary: 'response'\n",
      "Error generating summary: 'response'\n",
      "parse function read file\n",
      "Error generating summary: 'response'\n",
      "Error generating summary: 'response'\n",
      "Generated 0 function summaries\n",
      "Summary generation complete. Found 0 functions.\n",
      "Saved 0 function summaries to function_summaries.json\n",
      "\n",
      "Sample summaries:\n"
     ]
    }
   ],
   "source": [
    "class ContextAwareFunctionSummaryGenerator: \n",
    "    '''\n",
    "    This module aims to generate a summary for each function in a repository. Only python files are supported. \n",
    "    To make the summary generation of each function context aware, we do a depth first search on the file system tree and appending the context for each \n",
    "    step of the traversal. The run function runs the whole module and stores the results in self.vectors. \n",
    "    '''\n",
    "    def __init__(self, ROOT, api):\n",
    "        self.ROOT = ROOT\n",
    "        self.api = api # api can be github api or local file system\n",
    "        self.tokenLimit = 1000\n",
    "        self.vectors: List[SummaryResult] = []\n",
    "    \n",
    "    def LLM_call(self, prompt: str):\n",
    "        try:\n",
    "            \n",
    "            url = \"http://localhost:11434/api/generate\"\n",
    "\n",
    "            # Correctly format the payload using json.dumps()\n",
    "            payload = json.dumps({\n",
    "                \"model\": \"llama3.2\",\n",
    "                \"prompt\": prompt,\n",
    "                \"stream\": False\n",
    "            })\n",
    "\n",
    "            headers = {\n",
    "                \"Content-Type\": \"application/json\"\n",
    "            }\n",
    "\n",
    "            response = requests.post(url, headers=headers, data=payload)\n",
    "            response = response.json()\n",
    "            summary = response[\"response\"]\n",
    "            \n",
    "            return summary\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating summary: {e}\")\n",
    "            return f\"Error generating summary: {e}\"\n",
    "    \n",
    "    def process_file(self, context: str, path: str):\n",
    "        '''\n",
    "        called when the traversal encounters a file.\n",
    "        calls self.parse to parse the file into list of function, summarizes each function, and store them in self.vectors. \n",
    "        '''\n",
    "        if not path.endswith('.py'):\n",
    "            return\n",
    "        \n",
    "        file_vectors: List[SummaryResult] = []\n",
    "\n",
    "        try:\n",
    "            functions = self.parse(path)\n",
    "            \n",
    "            # Add file-specific information to context\n",
    "            file_context = f\"{context}\\nFile: {path}\\n\"\n",
    "            \n",
    "            for func in functions:\n",
    "                summary_result = self.summarize(file_context, func)\n",
    "                file_vectors.append(summary_result)\n",
    "            current_token_count = sum([len(enc.encode(vector.summary)) for vector in file_vectors])            \n",
    "            while( self.tokenLimit < current_token_count):\n",
    "                \n",
    "                shortened_file_vectors: List[SummaryResult] = []\n",
    "                for vector in file_vectors:\n",
    "                    # shorten each vector\n",
    "                    prompt = f\"\"\"\"\"\n",
    "                    We have a collection of summaries of functions in file whose token count is {current_token_count}. We cannot exceed this amount of tokens: {self.tokenLimit}\n",
    "                    Please shorten the following individual summary by a reasonable amount while retaining meaning: \n",
    "                    {vector.summary}                    \"\"\"\n",
    "                    summary = self.LLM_call(prompt)\n",
    "                    new_vector = SummaryResult(\n",
    "                        summary=summary,\n",
    "                        code=vector.code,\n",
    "                        metadata=vector.metadata\n",
    "                    )\n",
    "                    shortened_file_vectors.append(new_vector)\n",
    "                \n",
    "                file_vectors = shortened_file_vectors\n",
    "                current_token_count = sum([len(enc.encode(vector.summary)) for vector in file_vectors])  \n",
    "\n",
    "            collection_of_summaries = \"\"\n",
    "            for vector in file_vectors: \n",
    "                collection_of_summaries += vector.summary + \"\\n\"\n",
    "            prompt = f\"\"\"\"\"\n",
    "            We have the following collection of summaries of each function within this file. Based on these summaries, give a brief summary of the file itself based on these summaries\n",
    "            Collections of Summaries: \n",
    "            {collection_of_summaries}\n",
    "            \"\"\"\n",
    "            file_summary = self.LLM_call(prompt)\n",
    "            \n",
    "            return file_summary\n",
    "        \n",
    "            \n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {path}: {e}\")\n",
    "\n",
    "    def process_dir(self, context: str, path: str): \n",
    "        '''\n",
    "        called when the traversal encounters a directory\n",
    "        processes the directory. \n",
    "        Calls process file for .py files in the directory.\n",
    "        Uses current files's context and relavant documentation to enrich the context. \n",
    "        Calls process_dir on subdirectories with the enriched context. \n",
    "        '''\n",
    "        import os\n",
    "        \n",
    "        try:\n",
    "            # Enhance context with directory information\n",
    "            dir_context = f\"{context}\\nDirectory: {path}\\n\"\n",
    "            \n",
    "            # Look for README or documentation to enhance context\n",
    "            readme_path = os.path.join(path, \"README.md\")\n",
    "            if os.path.exists(readme_path):\n",
    "                try:\n",
    "                    with open(readme_path, 'r') as f:\n",
    "                        readme_content = f.read()\n",
    "                    dir_context += f\"\\nREADME: {readme_content}\\n\"\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading README {readme_path}: {e}\")\n",
    "            \n",
    "            # Process all items in the directory\n",
    "            for item in os.listdir(path):\n",
    "                item_path = os.path.join(path, item)\n",
    "                \n",
    "                # Skip hidden files and directories\n",
    "                if item.startswith('.'):\n",
    "                    continue\n",
    "                \n",
    "                if os.path.isfile(item_path):\n",
    "                    self.process_file(dir_context, item_path)\n",
    "                elif os.path.isdir(item_path):\n",
    "                    self.process_dir(dir_context, item_path)\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing directory {path}: {e}\")\n",
    "\n",
    "    def parse(self, file_path) -> List[str]: \n",
    "        '''\n",
    "        parse a .py file using the AST module into a list of strings, each string\n",
    "        containing the code of a function \n",
    "        '''\n",
    "        import ast\n",
    "        \n",
    "        functions = []\n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                file_content = f.read()\n",
    "                print(\"parse function read file\")\n",
    "                \n",
    "            tree = ast.parse(file_content)\n",
    "            lines = file_content.splitlines()\n",
    "            \n",
    "            for node in ast.walk(tree):\n",
    "                if isinstance(node, ast.FunctionDef):\n",
    "                    # Get start line (1-based indexing in AST, convert to 0-indexed)\n",
    "                    start_line = node.lineno - 1\n",
    "                    \n",
    "                    # Find function end based on indentation\n",
    "                    base_indent = None\n",
    "                    end_line = len(lines)\n",
    "                    \n",
    "                    # Get the indentation of the function definition line\n",
    "                    first_line = lines[start_line]\n",
    "                    base_indent = len(first_line) - len(first_line.lstrip())\n",
    "                    \n",
    "                    # Find the end of the function\n",
    "                    for i, line in enumerate(lines[start_line + 1:], start_line + 1):\n",
    "                        if not line.strip() or line.strip().startswith('#'):\n",
    "                            continue\n",
    "                            \n",
    "                        curr_indent = len(line) - len(line.lstrip())\n",
    "                        if curr_indent <= base_indent:\n",
    "                            end_line = i\n",
    "                            break\n",
    "                    \n",
    "                    function_code = '\\n'.join(lines[start_line:end_line])\n",
    "                    functions.append(function_code)\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing file {file_path}: {e}\")\n",
    "            \n",
    "        return functions\n",
    "\n",
    "    def summarize(self, context: str, target: str) -> SummaryResult:\n",
    "        '''\n",
    "        @params: \n",
    "        context: contextual information about the codebase\n",
    "        target: the function string to be summarized\n",
    "        Use LLM to summarize the target \n",
    "        '''\n",
    "        prompt = f\"\"\"\n",
    "        Given the following context about a codebase:\n",
    "        Context is in the form of the current file's path followed by available summaries of ancestor directory files.\n",
    "        {context}\n",
    "        \n",
    "        Please provide a concise summary for this function:\n",
    "        ```python\n",
    "        {target}\n",
    "        ```\n",
    "        \n",
    "        Provide a clear description of:\n",
    "        1. What the function does (purpose)\n",
    "        2. Input parameters and their types\n",
    "        3. Return value and type\n",
    "        4. Any side effects\n",
    "        5. How it relates to the rest of the codebase based on the context\n",
    "        \n",
    "        Format your response as a concise paragraph.\n",
    "        \"\"\"\n",
    "        \n",
    "        summary = self.LLM_call(prompt)\n",
    "\n",
    "        return SummaryResult(\n",
    "            summary=summary,\n",
    "            code=target,\n",
    "            metadata={\"context\":context}\n",
    "        ) \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    def run(self) -> None: \n",
    "        '''\n",
    "        runs the whole workflow\n",
    "        '''\n",
    "        print(f\"Starting code summary generation for repository: {self.ROOT}\")\n",
    "        \n",
    "        initial_context = f\"Repository: {self.ROOT}\\n\"\n",
    "        \n",
    "        # Start processing from the root directory\n",
    "        self.process_dir(initial_context, self.ROOT)\n",
    "        \n",
    "        print(f\"Generated {len(self.vectors)} function summaries\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Repository path to analyze\n",
    "    repo_path = os.path.abspath(\".\")\n",
    "    \n",
    "    # Initialize the summary generator\n",
    "    # Using None for api since we're working with local filesystem\n",
    "    generator = ContextAwareFunctionSummaryGenerator(ROOT=repo_path, api=None)\n",
    "    \n",
    "    # Run the summary generation process\n",
    "    generator.run()\n",
    "    \n",
    "    print(f\"Summary generation complete. Found {len(generator.vectors)} functions.\")\n",
    "    \n",
    "    # Save the results to a JSON file\n",
    "    results = [\n",
    "        {\n",
    "            \"summary\": item.summary,\n",
    "            \"code\": item.code,\n",
    "            \"file_path\": item.metadata.get(\"context\", \"\").split(\"File: \")[-1].split(\"\\n\")[0] if \"File: \" in item.metadata.get(\"context\", \"\") else \"unknown\",\n",
    "            \"repository\": repo_path\n",
    "        }\n",
    "        for item in generator.vectors\n",
    "    ]\n",
    "    \n",
    "    # Save to file\n",
    "    output_file = \"function_summaries.json\"\n",
    "    with open(output_file, \"w\") as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    \n",
    "    print(f\"Saved {len(results)} function summaries to {output_file}\")\n",
    "    \n",
    "    # Display a few examples\n",
    "    print(\"\\nSample summaries:\")\n",
    "    for i, result in enumerate(results[:3]):\n",
    "        print(f\"\\n--- Function {i+1} ---\")\n",
    "        print(f\"File: {result['file_path']}\")\n",
    "        print(f\"Summary: {result['summary'][:150]}...\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = ContextAwareFunctionSummaryGenerator(ROOT=os.getcwd(), api=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parse function read file\n",
      "import requests\n",
      "import json\n",
      "import time\n",
      "from collections import deque\n",
      "\n",
      "class WeatherDataProcessor:\n",
      "    def __init__(self, api_key, cache_size=5):\n",
      " \n",
      "        self.api_key = api_key\n",
      "        self.cache = deque(maxlen=cache_size)\n",
      "\n",
      "    def fetch_weather_data(self, city):\n",
      "\n",
      "        url = f\"https://api.openweathermap.org/data/2.5/weather?q={city}&appid={self.api_key}\"\n",
      "        response = requests.get(url)\n",
      "        \n",
      "        if response.status_code == 200:\n",
      "            data = response.json()\n",
      "            self.cache.append((city, data, time.time()))\n",
      "            return data\n",
      "        else:\n",
      "            raise ValueError(f\"Failed to fetch weather data for {city}\")\n",
      "\n",
      "    def get_cached_weather(self, city):\n",
      " \n",
      "        for cached_city, data, timestamp in self.cache:\n",
      "            if cached_city == city and time.time() - timestamp < 600:  # 10-minute cache\n",
      "                return data\n",
      "        return None\n",
      "\n",
      "    def analyze_weather(self, weather_data):\n",
      "\n",
      "        temp = weather_data[\"main\"][\"temp\"] - 273.15  # Convert Kelvin to Celsius\n",
      "        conditions = weather_data[\"weather\"][0][\"description\"]\n",
      "        wind_speed = weather_data[\"wind\"][\"speed\"]\n",
      "\n",
      "        summary = f\"Temperature: {temp:.2f}Â°C, Conditions: {conditions}, Wind Speed: {wind_speed} m/s.\"\n",
      "        if temp > 30:\n",
      "            summary += \" It's quite hot today!\"\n",
      "        elif temp < 10:\n",
      "            summary += \" It's quite chilly!\"\n",
      "        return summary\n",
      "\n",
      "    def get_weather_summary(self, city):\n",
      " \n",
      "        cached_data = self.get_cached_weather(city)\n",
      "        if cached_data:\n",
      "            return \"Cached Data: \" + self.analyze_weather(cached_data)\n",
      "        \n",
      "        try:\n",
      "            weather_data = self.fetch_weather_data(city)\n",
      "            return self.analyze_weather(weather_data)\n",
      "        except ValueError as e:\n",
      "            return str(e)\n",
      "Parsed Functions:\n",
      "\n",
      "Error generating summary: 'response'\n",
      "Error generating summary: 'response'\n",
      "Error generating summary: 'response'\n",
      "Error generating summary: 'response'\n",
      "Error generating summary: 'response'\n",
      "Error generating summary: 'response'\n",
      "Error generating summary: 'response'\n",
      "Error generating summary: 'response'\n",
      "Error generating summary: 'response'\n",
      "Error generating summary: 'response'\n"
     ]
    }
   ],
   "source": [
    "parsed_functions = generator.parse(\"test.py\")\n",
    "with open(\"test.py\", 'r') as f:\n",
    "    file_content = f.read()\n",
    "    print(file_content)\n",
    "\n",
    "print(\"Parsed Functions:\\n\")\n",
    "for i, func in enumerate(parsed_functions, 1):\n",
    "    context = \"File Path: './'\" \\\n",
    "    \"Summary: \"\n",
    "\n",
    "    print((generator.summarize(context, func)).summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on these summaries, this file is likely part of a Python-based project that interacts with an OpenWeatherMap API to manage and display weather data for various cities. The code appears to utilize caching mechanisms to improve efficiency and reduce the number of requests made to the API.\n",
      "\n",
      "The file contains functions that:\n",
      "\n",
      "1. Initialize an instance of a class with an API key and optional cache size parameter.\n",
      "2. Fetch current weather data from the OpenWeatherMap API for a given city, caching responses when possible.\n",
      "3. Retrieve cached weather data for a given city, with a 10-minute expiration time.\n",
      "4. Analyze weather data by converting temperature to Celsius, extracting weather descriptions, and calculating wind speed.\n",
      "5. Combine cached weather data with an analysis of the latest weather data for a specified city.\n",
      "\n",
      "The overall purpose of this file is to provide a flexible and efficient way to manage and display weather data for various cities, leveraging caching and external API connections as needed.\n"
     ]
    }
   ],
   "source": [
    "print(generator.process_file(\"\", \"./test.py\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
