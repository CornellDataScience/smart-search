{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2j6jMksH2giX"
      },
      "source": [
        "### Sample Data Used in Below Examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NvAEd4ZV2kYP"
      },
      "outputs": [],
      "source": [
        "data = [\n",
        "    \"Function that randomly generates a list of integers\",\n",
        "    \"Function that makes calls to the OpenAI API for summary generation\",\n",
        "    \"Function that manages textual context as a directory is navigated through DFS\",\n",
        "    \"Function that prints current textual context\",\n",
        "    \"Function that scans a document for LaTeX texts\"\n",
        "]\n",
        "\n",
        "metadatas = [\n",
        "    {\n",
        "        \"source\" : \"source 1\",\n",
        "        \"code\" : \"source code 1\",\n",
        "        \"date\" : \"2025-03-04\"\n",
        "    },\n",
        "    {\n",
        "        \"source\" : \"source 2\",\n",
        "        \"code\" : \"source code 2\",\n",
        "        \"date\" : \"2025-03-04\"\n",
        "    },\n",
        "    {\n",
        "        \"source\" : \"source 3\",\n",
        "        \"code\" : \"source code 3\",\n",
        "        \"date\" : \"2025-03-04\"\n",
        "    },\n",
        "    {\n",
        "        \"source\" : \"source 4\",\n",
        "        \"code\" : \"source code 4\",\n",
        "        \"date\" : \"2025-03-04\"\n",
        "    },\n",
        "    {\n",
        "        \"source\" : \"source 5\",\n",
        "        \"code\" : \"source code 5\",\n",
        "        \"date\" : \"2025-03-04\"\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaT4WLa-0vK8"
      },
      "source": [
        "### Chroma Vector Database Usage\n",
        "- Free, local\n",
        "- Metadata filtering possible\n",
        "- Search results are returned in somewhat annoying format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uSKGU-D07jtH"
      },
      "outputs": [],
      "source": [
        "pip install datetime chromadb --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xNA36-vm7lsE"
      },
      "outputs": [],
      "source": [
        "# ChromaDB offers metadata filtering\n",
        "# https://docs.trychroma.com/docs/overview/introduction\n",
        "\n",
        "from datetime import datetime\n",
        "import chromadb\n",
        "import chromadb.utils.embedding_functions as embedding_functions\n",
        "\n",
        "chroma_client = chromadb.Client()\n",
        "\n",
        "# # Need API Key\n",
        "# openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
        "#     api_key=\"YOUR_API_KEY\",\n",
        "#     model_name=\"text-embedding-3-small\"\n",
        "# )\n",
        "\n",
        "# With huggingface embeddings, in case we ever transition to open source implementation\n",
        "huggingface_ef = embedding_functions.HuggingFaceEmbeddingFunction(\n",
        "    api_key=\"\",\n",
        "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
        ")\n",
        "\n",
        "collection = chroma_client.get_or_create_collection(\n",
        "    name=\"test\",\n",
        "    embedding_function = huggingface_ef,\n",
        "    metadata={\n",
        "        \"hnsw:space\": \"cosine\"\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7tEhThl51Mg1"
      },
      "outputs": [],
      "source": [
        "now = datetime.now()\n",
        "collection.add(\n",
        "    documents= data,\n",
        "    metadatas= metadatas,\n",
        "    ids= [now.strftime(\"%Y-%m-%d %H:%M:%S\") + \"id\" + str(i) for i in range(5)]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMYplFav7nxU",
        "outputId": "d8e54994-de48-472b-8741-bf406217130c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'ids': [['2025-03-10 16:19:48id1',\n",
              "   '2025-03-10 16:19:48id3',\n",
              "   '2025-03-10 16:19:48id4',\n",
              "   '2025-03-10 16:19:48id2',\n",
              "   '2025-03-10 16:19:48id0']],\n",
              " 'embeddings': None,\n",
              " 'documents': [['Function that makes calls to the OpenAI API for summary generation',\n",
              "   'Function that prints current textual context',\n",
              "   'Function that scans a document for LaTeX texts',\n",
              "   'Function that manages textual context as a directory is navigated through DFS',\n",
              "   'Function that randomly generates a list of integers']],\n",
              " 'uris': None,\n",
              " 'data': None,\n",
              " 'metadatas': [[{'code': 'source code 2',\n",
              "    'date': '2025-03-04',\n",
              "    'source': 'source 2'},\n",
              "   {'code': 'source code 4', 'date': '2025-03-04', 'source': 'source 4'},\n",
              "   {'code': 'source code 5', 'date': '2025-03-04', 'source': 'source 5'},\n",
              "   {'code': 'source code 3', 'date': '2025-03-04', 'source': 'source 3'},\n",
              "   {'code': 'source code 1', 'date': '2025-03-04', 'source': 'source 1'}]],\n",
              " 'distances': [[0.6876525282859802,\n",
              "   0.7072367072105408,\n",
              "   0.7780947685241699,\n",
              "   0.804670512676239,\n",
              "   0.936271071434021]],\n",
              " 'included': [<IncludeEnum.distances: 'distances'>,\n",
              "  <IncludeEnum.documents: 'documents'>,\n",
              "  <IncludeEnum.metadatas: 'metadatas'>]}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results = collection.query(\n",
        "    query_texts=[\"How does the library come up with the code summaries?\"],\n",
        "    n_results=5\n",
        ")\n",
        "\n",
        "results\n",
        "\n",
        "# Can look at all documents inserted into the vector database with peek()\n",
        "# collection.peek()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lp-dgAP80eZB"
      },
      "source": [
        "### FAISS Vector Database Integration in LangChain\n",
        "- Thought one example using LangChain could be helpful since it seemed that LangChain / LangGraph could eventually be in the books\n",
        "- Filtering with metadata also possible"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "W9Dt1cH1ogkU"
      },
      "outputs": [],
      "source": [
        "pip install --upgrade --quiet  sentence_transformers langchain_huggingface langchain_community faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "lbGEbzfaojC9"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "# If we get access to a GPU, we can use the GPU implementation to accelerate search\n",
        "model_kwargs = {'device': 'cpu'}\n",
        "encode_kwargs = {'normalize_embeddings': False}\n",
        "hf_embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=model_name,\n",
        "    model_kwargs=model_kwargs,\n",
        "    encode_kwargs=encode_kwargs\n",
        ")\n",
        "\n",
        "# LangChain Integration of FAISS\n",
        "# db = FAISS.from_texts(texts = data, embedding = hf_embeddings)\n",
        "\n",
        "# Alternatively, can setup documents with\n",
        "docs = [Document(page_content = text, metadata = metadata) for text, metadata in zip(data, metadatas)]\n",
        "db = FAISS.from_documents(documents = docs, embedding = hf_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdeNzSr8rIw_",
        "outputId": "44a17313-2479-40b9-a7cb-586e82126236"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(id='602c63d6-8534-475a-a5b4-360fb59b49e1', metadata={'source': 'source 2', 'code': 'source code 2', 'date': '2025-03-04'}, page_content='Function that makes calls to the OpenAI API for summary generation'),\n",
              " Document(id='a0cd807c-826d-42c0-b69a-7c94100b7bc3', metadata={'source': 'source 4', 'code': 'source code 4', 'date': '2025-03-04'}, page_content='Function that prints current textual context'),\n",
              " Document(id='1e75ee8d-e248-4a31-aba4-9ce9810fe9c2', metadata={'source': 'source 5', 'code': 'source code 5', 'date': '2025-03-04'}, page_content='Function that scans a document for LaTeX texts'),\n",
              " Document(id='a93d51f8-afff-468f-856f-1e8c8b54f07a', metadata={'source': 'source 3', 'code': 'source code 3', 'date': '2025-03-04'}, page_content='Function that manages textual context as a directory is navigated through DFS')]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "db.similarity_search(\"How does the library come up with the code summaries?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DToQdrk3J7j",
        "outputId": "1ecea59d-2dcb-4938-99e5-658ea0fe1cd7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(id='1e75ee8d-e248-4a31-aba4-9ce9810fe9c2', metadata={'source': 'source 5', 'code': 'source code 5', 'date': '2025-03-04'}, page_content='Function that scans a document for LaTeX texts')]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "db.similarity_search(query=\"How does the library come up with the code summaries?\", k=3,filter={\"source\" : \"source 5\"})"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "2j6jMksH2giX",
        "VaT4WLa-0vK8",
        "lp-dgAP80eZB"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
