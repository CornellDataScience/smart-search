{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import ollama\n",
    "from pydantic import BaseModel\n",
    "import os \n",
    "import json \n",
    "import requests\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummaryResult(BaseModel):\n",
    "    summary: str\n",
    "    code: str\n",
    "    metadata: dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting code summary generation for repository: /Users/srikarkarra/Documents/CDS/smart-search/your_target_repository\n",
      "Error processing directory /Users/srikarkarra/Documents/CDS/smart-search/your_target_repository: [Errno 2] No such file or directory: '/Users/srikarkarra/Documents/CDS/smart-search/your_target_repository'\n",
      "Generated 0 function summaries\n",
      "Summary generation complete. Found 0 functions.\n",
      "Saved 0 function summaries to function_summaries.json\n",
      "\n",
      "Sample summaries:\n"
     ]
    }
   ],
   "source": [
    "class ContextAwareFunctionSummaryGenerator: \n",
    "    '''\n",
    "    This module aims to generate a summary for each function in a repository. Only python files are supported. \n",
    "    To make the summary generation of each function context aware, we do a depth first search on the file system tree and appending the context for each \n",
    "    step of the traversal. The run function runs the whole module and stores the results in self.vectors. \n",
    "    '''\n",
    "    def __init__(self, ROOT, api):\n",
    "        self.ROOT = ROOT\n",
    "        self.api = api # api can be github api or local file system\n",
    "        self.tokenLimit = 1000\n",
    "        self.vectors: List[SummaryResult] = []\n",
    "    \n",
    "    def LLM_call(self, prompt: str):\n",
    "        try:\n",
    "            \n",
    "            url = \"http://localhost:11434/api/generate\"\n",
    "\n",
    "            # Correctly format the payload using json.dumps()\n",
    "            payload = json.dumps({\n",
    "                \"model\": \"llama3.2\",\n",
    "                \"prompt\": prompt,\n",
    "                \"stream\": False\n",
    "            })\n",
    "\n",
    "            headers = {\n",
    "                \"Content-Type\": \"application/json\"\n",
    "            }\n",
    "\n",
    "            response = requests.post(url, headers=headers, data=payload)\n",
    "            response = response.json()\n",
    "            summary = response[\"response\"]\n",
    "            \n",
    "            return summary\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating summary: {e}\")\n",
    "            return f\"Error generating summary: {e}\"\n",
    "    \n",
    "    def process_file(self, context: str, path: str):\n",
    "        '''\n",
    "        called when the traversal encounters a file.\n",
    "        calls self.parse to parse the file into list of function, summarizes each function, and store them in self.vectors. \n",
    "        '''\n",
    "        if not path.endswith('.py'):\n",
    "            return\n",
    "        \n",
    "        file_vectors: List[SummaryResult] = []\n",
    "\n",
    "        try:\n",
    "            functions = self.parse(path)\n",
    "            \n",
    "            # Add file-specific information to context\n",
    "            file_context = f\"{context}\\nFile: {path}\\n\"\n",
    "            \n",
    "            for func in functions:\n",
    "                summary_result = self.summarize(file_context, func)\n",
    "                file_vectors.append(summary_result)\n",
    "            current_token_count = sum([len(enc.encode(vector.summary)) for vector in file_vectors])            \n",
    "            while( self.tokenLimit < current_token_count):\n",
    "                \n",
    "                shortened_file_vectors: List[SummaryResult] = []\n",
    "                for vector in file_vectors:\n",
    "                    # shorten each vector\n",
    "                    prompt = f\"\"\"\"\"\n",
    "                    We have a collection of summaries of functions in file whose token count is {current_token_count}. We cannot exceed this amount of tokens: {self.tokenLimit}\n",
    "                    Please shorten the following individual summary by a reasonable amount while retaining meaning: \n",
    "                    {vector.summary}                    \"\"\"\n",
    "                    summary = self.LLM_call(prompt)\n",
    "                    new_vector = SummaryResult(\n",
    "                        summary=summary,\n",
    "                        code=vector.code,\n",
    "                        metadata=vector.metadata\n",
    "                    )\n",
    "                    shortened_file_vectors.append(new_vector)\n",
    "                \n",
    "                file_vectors = shortened_file_vectors\n",
    "                current_token_count = sum([len(enc.encode(vector.summary)) for vector in file_vectors])  \n",
    "\n",
    "            collection_of_summaries = \"\"\n",
    "            for vector in file_vectors: \n",
    "                collection_of_summaries += vector.summary + \"\\n\"\n",
    "            prompt = f\"\"\"\"\"\n",
    "            We have the following collection of summaries of each function within this file. Based on these summaries, give a brief summary of the file itself based on these summaries\n",
    "            Collections of Summaries: \n",
    "            {collection_of_summaries}\n",
    "            \"\"\"\n",
    "            file_summary = self.LLM_call(prompt)\n",
    "            \n",
    "            return file_summary\n",
    "        \n",
    "            \n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {path}: {e}\")\n",
    "\n",
    "    def process_dir(self, context: str, path: str): \n",
    "        '''\n",
    "        called when the traversal encounters a directory\n",
    "        processes the directory. \n",
    "        Calls process file for .py files in the directory.\n",
    "        Uses current files's context and relavant documentation to enrich the context. \n",
    "        Calls process_dir on subdirectories with the enriched context. \n",
    "        '''\n",
    "        import os\n",
    "        \n",
    "        try:\n",
    "            # Enhance context with directory information\n",
    "            dir_context = f\"{context}\\nDirectory: {path}\\n\"\n",
    "            \n",
    "            # Look for README or documentation to enhance context\n",
    "            readme_path = os.path.join(path, \"README.md\")\n",
    "            if os.path.exists(readme_path):\n",
    "                try:\n",
    "                    with open(readme_path, 'r') as f:\n",
    "                        readme_content = f.read()\n",
    "                    dir_context += f\"\\nREADME: {readme_content}\\n\"\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading README {readme_path}: {e}\")\n",
    "            \n",
    "            # Process all items in the directory\n",
    "            for item in os.listdir(path):\n",
    "                item_path = os.path.join(path, item)\n",
    "                \n",
    "                # Skip hidden files and directories\n",
    "                if item.startswith('.'):\n",
    "                    continue\n",
    "                \n",
    "                if os.path.isfile(item_path):\n",
    "                    self.process_file(dir_context, item_path)\n",
    "                elif os.path.isdir(item_path):\n",
    "                    self.process_dir(dir_context, item_path)\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing directory {path}: {e}\")\n",
    "\n",
    "    def parse(self, file_path) -> List[str]: \n",
    "        '''\n",
    "        parse a .py file using the AST module into a list of strings, each string\n",
    "        containing the code of a function \n",
    "        '''\n",
    "        import ast\n",
    "        \n",
    "        functions = []\n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                file_content = f.read()\n",
    "                \n",
    "            tree = ast.parse(file_content)\n",
    "            lines = file_content.splitlines()\n",
    "            \n",
    "            for node in ast.walk(tree):\n",
    "                if isinstance(node, ast.FunctionDef):\n",
    "                    # Get start line (1-based indexing in AST, convert to 0-indexed)\n",
    "                    start_line = node.lineno - 1\n",
    "                    \n",
    "                    # Find function end based on indentation\n",
    "                    base_indent = None\n",
    "                    end_line = len(lines)\n",
    "                    \n",
    "                    # Get the indentation of the function definition line\n",
    "                    first_line = lines[start_line]\n",
    "                    base_indent = len(first_line) - len(first_line.lstrip())\n",
    "                    \n",
    "                    # Find the end of the function\n",
    "                    for i, line in enumerate(lines[start_line + 1:], start_line + 1):\n",
    "                        if not line.strip() or line.strip().startswith('#'):\n",
    "                            continue\n",
    "                            \n",
    "                        curr_indent = len(line) - len(line.lstrip())\n",
    "                        if curr_indent <= base_indent:\n",
    "                            end_line = i\n",
    "                            break\n",
    "                    \n",
    "                    function_code = '\\n'.join(lines[start_line:end_line])\n",
    "                    functions.append(function_code)\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing file {file_path}: {e}\")\n",
    "            \n",
    "        return functions\n",
    "\n",
    "    def summarize(self, context: str, target: str) -> SummaryResult:\n",
    "        '''\n",
    "        @params: \n",
    "        context: contextual information about the codebase\n",
    "        target: the function string to be summarized\n",
    "        Use LLM to summarize the target \n",
    "        '''\n",
    "        prompt = f\"\"\"\n",
    "        Given the following context about a codebase:\n",
    "        Context is in the form of the current file's path followed by available summaries of ancestor directory files.\n",
    "        {context}\n",
    "        \n",
    "        Please provide a concise summary for this function:\n",
    "        ```python\n",
    "        {target}\n",
    "        ```\n",
    "        \n",
    "        Provide a clear description of:\n",
    "        1. What the function does (purpose)\n",
    "        2. Input parameters and their types\n",
    "        3. Return value and type\n",
    "        4. Any side effects\n",
    "        5. How it relates to the rest of the codebase based on the context\n",
    "        \n",
    "        Format your response as a concise paragraph.\n",
    "        \"\"\"\n",
    "        \n",
    "        summary = self.LLM_call(prompt)\n",
    "\n",
    "        return SummaryResult(\n",
    "            summary=summary,\n",
    "            code=target,\n",
    "            metadata={\"context\":context}\n",
    "        ) \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    def run(self) -> None: \n",
    "        '''\n",
    "        runs the whole workflow\n",
    "        '''\n",
    "        print(f\"Starting code summary generation for repository: {self.ROOT}\")\n",
    "        \n",
    "        initial_context = f\"Repository: {self.ROOT}\\n\"\n",
    "        \n",
    "        # Start processing from the root directory\n",
    "        self.process_dir(initial_context, self.ROOT)\n",
    "        \n",
    "        print(f\"Generated {len(self.vectors)} function summaries\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Repository path to analyze\n",
    "    repo_path = os.path.abspath(\"./your_target_repository\")\n",
    "    \n",
    "    # Initialize the summary generator\n",
    "    # Using None for api since we're working with local filesystem\n",
    "    generator = ContextAwareFunctionSummaryGenerator(ROOT=repo_path, api=None)\n",
    "    \n",
    "    # Run the summary generation process\n",
    "    generator.run()\n",
    "    \n",
    "    print(f\"Summary generation complete. Found {len(generator.vectors)} functions.\")\n",
    "    \n",
    "    # Save the results to a JSON file\n",
    "    results = [\n",
    "        {\n",
    "            \"summary\": item.summary,\n",
    "            \"code\": item.code,\n",
    "            \"file_path\": item.metadata.get(\"context\", \"\").split(\"File: \")[-1].split(\"\\n\")[0] if \"File: \" in item.metadata.get(\"context\", \"\") else \"unknown\",\n",
    "            \"repository\": repo_path\n",
    "        }\n",
    "        for item in generator.vectors\n",
    "    ]\n",
    "    \n",
    "    # Save to file\n",
    "    output_file = \"function_summaries.json\"\n",
    "    with open(output_file, \"w\") as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    \n",
    "    print(f\"Saved {len(results)} function summaries to {output_file}\")\n",
    "    \n",
    "    # Display a few examples\n",
    "    print(\"\\nSample summaries:\")\n",
    "    for i, result in enumerate(results[:3]):\n",
    "        print(f\"\\n--- Function {i+1} ---\")\n",
    "        print(f\"File: {result['file_path']}\")\n",
    "        print(f\"Summary: {result['summary'][:150]}...\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = ContextAwareFunctionSummaryGenerator(ROOT=os.getcwd(), api=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed Functions:\n",
      "\n",
      "This function is an initializer for a class that likely handles API interactions, given the `api_key` parameter and the use of a cache with a limited size. The purpose of this function is to set up the class instance by storing the provided `api_key` and initializing a cache data structure using a deque from the `collections` module. The cache size can be customized through the `cache_size` parameter, which defaults to 5. There are no return values associated with this function, meaning it does not produce output directly. Instead, its purpose is to initialize internal state for the class instance, which will likely be accessed and manipulated by other methods in the class.\n",
      "This function, `fetch_weather_data`, retrieves weather data for a specified city using the OpenWeatherMap API. It takes two parameters: `self` (a reference to the instance of the class this method belongs to) and `city` (a string representing the name of the city). The function returns a JSON object containing the weather data, or raises a ValueError if the request fails. The method appends the fetched data to the cache along with its timestamp, suggesting that it is part of a caching mechanism. This function relies on external resources and has side effects by modifying the instance's cache. It seems to be related to a class-based implementation of some kind of weather service or API wrapper, possibly utilizing the OpenWeatherMap API for city-specific weather data.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[101]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, func \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(parsed_functions, \u001b[32m1\u001b[39m):\n\u001b[32m      5\u001b[39m     context = \u001b[33m\"\u001b[39m\u001b[33mFile Path: \u001b[39m\u001b[33m'\u001b[39m\u001b[33m./\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m \\\n\u001b[32m      6\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mSummary: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     \u001b[38;5;28mprint\u001b[39m((\u001b[43mgenerator\u001b[49m\u001b[43m.\u001b[49m\u001b[43msummarize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m).summary)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[99]\u001b[39m\u001b[32m, line 208\u001b[39m, in \u001b[36mContextAwareFunctionSummaryGenerator.summarize\u001b[39m\u001b[34m(self, context, target)\u001b[39m\n\u001b[32m    182\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m'''\u001b[39;00m\n\u001b[32m    183\u001b[39m \u001b[33;03m@params: \u001b[39;00m\n\u001b[32m    184\u001b[39m \u001b[33;03mcontext: contextual information about the codebase\u001b[39;00m\n\u001b[32m    185\u001b[39m \u001b[33;03mtarget: the function string to be summarized\u001b[39;00m\n\u001b[32m    186\u001b[39m \u001b[33;03mUse LLM to summarize the target \u001b[39;00m\n\u001b[32m    187\u001b[39m \u001b[33;03m'''\u001b[39;00m\n\u001b[32m    188\u001b[39m prompt = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[33mGiven the following context about a codebase:\u001b[39m\n\u001b[32m    190\u001b[39m \u001b[33mContext is in the form of the current file\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms path followed by available summaries of ancestor directory files.\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    205\u001b[39m \u001b[33mFormat your response as a concise paragraph.\u001b[39m\n\u001b[32m    206\u001b[39m \u001b[33m\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m summary = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mLLM_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m SummaryResult(\n\u001b[32m    211\u001b[39m     summary=summary,\n\u001b[32m    212\u001b[39m     code=target,\n\u001b[32m    213\u001b[39m     metadata={\u001b[33m\"\u001b[39m\u001b[33mcontext\u001b[39m\u001b[33m\"\u001b[39m:context}\n\u001b[32m    214\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[99]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mContextAwareFunctionSummaryGenerator.LLM_call\u001b[39m\u001b[34m(self, prompt)\u001b[39m\n\u001b[32m     19\u001b[39m payload = json.dumps({\n\u001b[32m     20\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mllama3.2\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     21\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m: prompt,\n\u001b[32m     22\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     23\u001b[39m })\n\u001b[32m     25\u001b[39m headers = {\n\u001b[32m     26\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mContent-Type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mapplication/json\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     27\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m response = response.json()\n\u001b[32m     31\u001b[39m summary = response[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/requests/api.py:115\u001b[39m, in \u001b[36mpost\u001b[39m\u001b[34m(url, data, json, **kwargs)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(url, data=\u001b[38;5;28;01mNone\u001b[39;00m, json=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m    104\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[32m    105\u001b[39m \n\u001b[32m    106\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    112\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/requests/api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/requests/adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    664\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/urllib3/connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.5/lib/python3.11/site-packages/urllib3/connection.py:516\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    513\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    515\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    519\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.5/lib/python3.11/http/client.py:1378\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1376\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1377\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1378\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1379\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1380\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.5/lib/python3.11/http/client.py:318\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    316\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    317\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m318\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    319\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    320\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.5/lib/python3.11/http/client.py:279\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m.fp.readline(_MAXLINE + \u001b[32m1\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    280\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    281\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.5/lib/python3.11/socket.py:706\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    704\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    705\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m706\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    708\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "parsed_functions = generator.parse(\"test.py\")\n",
    "\n",
    "print(\"Parsed Functions:\\n\")\n",
    "for i, func in enumerate(parsed_functions, 1):\n",
    "    context = \"File Path: './'\" \\\n",
    "    \"Summary: \"\n",
    "\n",
    "    print((generator.summarize(context, func)).summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on these summaries, this file is likely part of a Python-based project that interacts with an OpenWeatherMap API to manage and display weather data for various cities. The code appears to utilize caching mechanisms to improve efficiency and reduce the number of requests made to the API.\n",
      "\n",
      "The file contains functions that:\n",
      "\n",
      "1. Initialize an instance of a class with an API key and optional cache size parameter.\n",
      "2. Fetch current weather data from the OpenWeatherMap API for a given city, caching responses when possible.\n",
      "3. Retrieve cached weather data for a given city, with a 10-minute expiration time.\n",
      "4. Analyze weather data by converting temperature to Celsius, extracting weather descriptions, and calculating wind speed.\n",
      "5. Combine cached weather data with an analysis of the latest weather data for a specified city.\n",
      "\n",
      "The overall purpose of this file is to provide a flexible and efficient way to manage and display weather data for various cities, leveraging caching and external API connections as needed.\n"
     ]
    }
   ],
   "source": [
    "print(generator.process_file(\"\", \"./test.py\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
