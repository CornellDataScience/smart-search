{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2j6jMksH2giX"
      },
      "source": [
        "### Sample Data Used in Below Examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvAEd4ZV2kYP"
      },
      "outputs": [],
      "source": [
        "data = [\n",
        "    \"Function that randomly generates a list of integers\",\n",
        "    \"Function that makes calls to the OpenAI API for summary generation\",\n",
        "    \"Function that manages textual context as a directory is navigated through DFS\",\n",
        "    \"Function that prints current textual context\",\n",
        "    \"Function that scans a document for LaTeX texts\"\n",
        "]\n",
        "\n",
        "metadatas = [\n",
        "    {\n",
        "        \"source\" : \"source 1\",\n",
        "        \"code\" : \"source code 1\",\n",
        "        \"date\" : \"2025-03-04\"\n",
        "    },\n",
        "    {\n",
        "        \"source\" : \"source 2\",\n",
        "        \"code\" : \"source code 2\",\n",
        "        \"date\" : \"2025-03-04\"\n",
        "    },\n",
        "    {\n",
        "        \"source\" : \"source 3\",\n",
        "        \"code\" : \"source code 3\",\n",
        "        \"date\" : \"2025-03-04\"\n",
        "    },\n",
        "    {\n",
        "        \"source\" : \"source 4\",\n",
        "        \"code\" : \"source code 4\",\n",
        "        \"date\" : \"2025-03-04\"\n",
        "    },\n",
        "    {\n",
        "        \"source\" : \"source 5\",\n",
        "        \"code\" : \"source code 5\",\n",
        "        \"date\" : \"2025-03-04\"\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaT4WLa-0vK8"
      },
      "source": [
        "### Chroma Vector Database Usage\n",
        "- Free, local\n",
        "- Metadata filtering possible\n",
        "- Search results are returned in somewhat annoying format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSKGU-D07jtH"
      },
      "outputs": [],
      "source": [
        "pip install datetime chromadb --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xNA36-vm7lsE"
      },
      "outputs": [],
      "source": [
        "# ChromaDB offers metadata filtering\n",
        "# https://docs.trychroma.com/docs/overview/introduction\n",
        "\n",
        "from datetime import datetime\n",
        "import chromadb\n",
        "import chromadb.utils.embedding_functions as embedding_functions\n",
        "\n",
        "chroma_client = chromadb.Client()\n",
        "\n",
        "# # Need API Key\n",
        "# openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
        "#     api_key=\"YOUR_API_KEY\",\n",
        "#     model_name=\"text-embedding-3-small\"\n",
        "# )\n",
        "\n",
        "# With huggingface embeddings, in case we ever transition to open source implementation\n",
        "huggingface_ef = embedding_functions.HuggingFaceEmbeddingFunction(\n",
        "    api_key=\"\",\n",
        "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
        ")\n",
        "\n",
        "collection = chroma_client.get_or_create_collection(\n",
        "    name=\"test\",\n",
        "    embedding_function = huggingface_ef,\n",
        "    metadata={\n",
        "        \"hnsw:space\": \"cosine\"\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tEhThl51Mg1"
      },
      "outputs": [],
      "source": [
        "now = datetime.now()\n",
        "collection.add(\n",
        "    documents= data,\n",
        "    metadatas= metadatas,\n",
        "    ids= [str(now) + \"-id-\" + str(i) for i in range(5)]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMYplFav7nxU",
        "outputId": "d8e54994-de48-472b-8741-bf406217130c"
      },
      "outputs": [],
      "source": [
        "results = collection.query(\n",
        "    query_texts=[\"How does the library come up with the code summaries?\"],\n",
        "    n_results=5\n",
        ")\n",
        "\n",
        "results\n",
        "\n",
        "# Can look at all documents inserted into the vector database with peek()\n",
        "# collection.peek()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lp-dgAP80eZB"
      },
      "source": [
        "### FAISS Vector Database Integration in LangChain\n",
        "- Thought one example using LangChain could be helpful since it seemed that LangChain / LangGraph could eventually be in the books\n",
        "- Filtering with metadata also possible"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9Dt1cH1ogkU"
      },
      "outputs": [],
      "source": [
        "pip install --upgrade --quiet  sentence_transformers langchain_huggingface langchain_community faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbGEbzfaojC9"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "# If we get access to a GPU, we can use the GPU implementation to accelerate search\n",
        "model_kwargs = {'device': 'cpu'}\n",
        "encode_kwargs = {'normalize_embeddings': False}\n",
        "hf_embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=model_name,\n",
        "    model_kwargs=model_kwargs,\n",
        "    encode_kwargs=encode_kwargs\n",
        ")\n",
        "\n",
        "# LangChain Integration of FAISS\n",
        "# db = FAISS.from_texts(texts = data, embedding = hf_embeddings)\n",
        "\n",
        "# Alternatively, can setup documents with\n",
        "docs = [Document(page_content = text, metadata = metadata) for text, metadata in zip(data, metadatas)]\n",
        "db = FAISS.from_documents(documents = docs, embedding = hf_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdeNzSr8rIw_",
        "outputId": "44a17313-2479-40b9-a7cb-586e82126236"
      },
      "outputs": [],
      "source": [
        "db.similarity_search(\"How does the library come up with the code summaries?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DToQdrk3J7j",
        "outputId": "1ecea59d-2dcb-4938-99e5-658ea0fe1cd7"
      },
      "outputs": [],
      "source": [
        "db.similarity_search(query=\"How does the library come up with the code summaries?\", k=3,filter={\"source\" : \"source 5\"})"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "2j6jMksH2giX",
        "VaT4WLa-0vK8",
        "lp-dgAP80eZB"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
